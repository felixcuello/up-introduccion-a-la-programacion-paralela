\input{../shared.tex/common_headers.tex}

\begin{document}

\begin{center}
    \LARGE\textbf{Programación Paralela} \\
    \Large{CUDA y paralelización de algoritmos} \\
    \normalsize{Segundo Semestre, 2025} \\
    \vspace{1em}
    \hrule
\end{center}

\vspace{1em}


%  FUNDAMENTACIÓN
% --------------------------------------------------------------------------------------------------
\section*{Fundamentación}
Las CPUs han sido desarrolladas para minimizar la latencia y maximizar el rendimiento de las aplicaciones secuenciales.
Sin embargo hay determinadas aplicaciones y algoritmos que sólo pueden ser optimizados si se corren de manera paralela.
Para ello se requieren tantos CPUs como GPUs, pero se necesitan lenguajes de programación y técnicas de programación
diferentes que las que se utilizan en las CPUs.

El objetivo de la materia Programación Paralela es introducir al alumno en el mundo de la programación paralela, basada
en arquitectura de GPUs. Se busca que el alumno adquiera los conocimientos necesarios para poder programar en CUDA, y
entender la forma en la que se deben abordar los problemas de programación paralela.

%  OBJETIVOS
% --------------------------------------------------------------------------------------------------
\section*{Objetivos}
\begin {itemize}
  \item Introducir al alumno a la programación paralela
  \item Comprender la arquitectura de las GPUs
  \item Aprender a programar en CUDA
  \item Entender cómo se deben abordar los problemas de programación paralela
  \item Conocer las técnicas de programación paralela
  \item Aprender a optimizar algoritmos
  \item Conocer las herramientas de programación paralela
  \item Realizar un proyecto de programación paralela
\end {itemize}


%  MODULO 01: INTRODUCCIÓN
% --------------------------------------------------------------------------------------------------
\subsection{Módulo 1: Introducción a la Programación Paralela}

\textbf{Límites del Paralelismo}: Complejidad polinomial, Clases P, Clases de Nick. \textbf{Introducción a la
Programación Paralela} Evolución de los microprocesadores y la escalabilidad vertical. Importancia del paralelismo
masivo y la elección de CUDA C. \textbf{Comparación entre CPUs y GPUs} Diferencias en optimización y rendimiento entre
CPUs y GPUs. Casos de uso y limitaciones de cada tipo de procesador. \textbf{Modelo de Programación CUDA} Descripción
del modelo de programación desarrollado por NVIDIA. Ventajas económicas y de rendimiento de utilizar GPUs con CUDA.
\textbf{Paralelización de Aplicaciones} Beneficios y limitaciones de la paralelización. Ley de Amdahl y su impacto en el
rendimiento de programas paralelos. \textbf{Desafíos en la Programación Paralela} Complejidad en el diseño de algoritmos
paralelos. Sensibilidad a los datos de entrada y límites de acceso a memoria.
\end{document}


%  MODULO 02: INTRODUCCIÓN A CUDA
% --------------------------------------------------------------------------------------------------
\subsection{Módulo 2: Introducción a CUDA}

\textbf{Estructura de Programas CUDA}: Modelo de programación heterogéneo con código para CPU (host) y GPU (device).
\textbf{Funciones Kernel y Threads}: Definición de funciones con \texttt{\_\_global\_\_}, \texttt{\_\_device\_\_} y
\texttt{\_\_host\_\_}. Organización de threads en bloques y grids para ejecución paralela. \textbf{Gestión de Memoria en
GPU}: Uso de \texttt{cudaMalloc}, \texttt{cudaFree} y \texttt{cudaMemcpy} para manejo de memoria global del device.
Transferencia de datos entre host y device. \textbf{Optimización de Algoritmos}: Patrones comunes de paralelismo como
reducción y loop-parallelism. \textbf{Aplicaciones Prácticas}: Implementación de operaciones vectoriales, procesamiento
de imágenes y otros algoritmos paralelizables. \textbf{Manejo de Errores}: Mejores prácticas para detectar y manejar
errores en código CUDA.


